{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffc692",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-google-genai langchain_community tavily-python aiosqlite langchain-tavily \n",
    "%pip install langgraph-checkpoint-sqlite \n",
    "%pip install langgraph langgraph-checkpoint-sqlite\n",
    "%pip install langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f1bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "import sqlite3 \n",
    "from langgraph.checkpoint.sqlite import SqliteSaver \n",
    "conn = sqlite3.connect(\"checkpoints.db\", check_same_thread=False) \n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4d6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY') \n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ce62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5.1-2025-11-13\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b73398",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"Você é um escritor especialista com a tarefa de criar um esboço de alto nível para uma redação. \\\n",
    "Escreva esse esboço para o tópico fornecido pelo usuário. Apresente um plano da redação junto com quaisquer notas \\\n",
    "ou instruções relevantes para as seções.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ab0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"Você é um assistente de redação com a tarefa de escrever excelentes redações de 5 parágrafos. \\\n",
    "Gere a melhor redação possível para a solicitação do usuário e o esboço inicial. \\\n",
    "Se o usuário fornecer críticas, responda com uma versão revisada das suas tentativas anteriores. \\\n",
    "Utilize todas as informações abaixo conforme necessário:\n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99501f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"Você é um professor corrigindo uma redação submetida. \\\n",
    "Gere uma crítica e recomendações para a submissão do usuário. \\\n",
    "Forneça recomendações detalhadas, incluindo pedidos sobre extensão, profundidade, estilo, etc.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7aa6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"Você é um pesquisador encarregado de fornecer informações que podem \\\n",
    "ser usadas ao escrever a seguinte redação. Gere uma lista de consultas de pesquisa que \\\n",
    "recolham quaisquer informações relevantes. Gere no máximo 3 consultas.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abe2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"Você é um pesquisador encarregado de fornecer informações que podem \\\n",
    "ser usadas ao fazer quaisquer revisões solicitadas (conforme descrito abaixo). \\\n",
    "Gere uma lista de consultas de pesquisa que recolham quaisquer informações relevantes. Gere no máximo 3 consultas.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f83e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3d9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd12b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c32233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4de733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5901fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6106c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33273fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dbb5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f31873",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d15773",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723ebf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display, Markdown\n",
    "import os\n",
    "\n",
    "print(\"\\n--- Tentando Gerar PNG do Grafo via Mermaid (Requer Playwright!) ---\")\n",
    "try:\n",
    "\n",
    "    image_data = graph.get_graph().draw_mermaid_png()\n",
    "    display(Image(data=image_data))\n",
    "    print(\"Grafo PNG gerado e exibido com sucesso!\")\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(f\"\\nErro ao tentar gerar o PNG do grafo: {e}\")\n",
    "    print(\"Isso pode ocorrer por:\")\n",
    "    print(\"1. O método `.draw_mermaid_png()` não existe na sua versão do LangGraph.\")\n",
    "    print(\"2. Faltam dependências como 'playwright' ou seus drivers não foram instalados.\")\n",
    "    print(\"   Tente: pip install playwright && playwright install\")\n",
    "    print(\"3. Outro erro inesperado ao acessar o grafo ou renderizar.\")\n",
    "\n",
    "    print(\"\\n--- Tentando gerar apenas o código Mermaid (Fallback) ---\")\n",
    "    try:\n",
    "\n",
    "        mermaid_code = graph.get_graph().draw_mermaid()\n",
    "        print(\"\\n--- Código Mermaid Gerado (Cole em https://mermaid.live/ ou use Markdown no notebook) ---\")\n",
    "        print(mermaid_code)\n",
    "\n",
    "    except Exception as e_mermaid:\n",
    "        print(f\"Erro ao gerar código Mermaid: {e_mermaid}\")\n",
    "        print(\"Verifique se 'graph.get_graph()' está correto e acessível.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"Qual é a diferença entre o langchain e langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "    \"content\": [], \n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f9a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
